{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811eb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.applications import InceptionV3, ResNet152, VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "img_size = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "n_clusters = 5\n",
    "max_seq_length = n_clusters\n",
    "NUM_FEATURES = 2048 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Features Function\n",
    "preprocessing_functions = {\n",
    "    'inception': preprocess_inception,\n",
    "    'vgg': preprocess_vgg,\n",
    "    'resnet': preprocess_resnet\n",
    "}\n",
    "\n",
    "def extract_features_from_frames(frames, model_name):\n",
    "    base_models = {\n",
    "        'inception': InceptionV3(weights='imagenet', include_top=False, pooling='avg'),\n",
    "        'vgg': VGG19(weights='imagenet', include_top=False, pooling='avg'),\n",
    "        'resnet': ResNet152(weights='imagenet', include_top=False, pooling='avg')\n",
    "    }\n",
    "    model = base_models[model_name]\n",
    "    frame_features = model.predict(frames)\n",
    "    return frame_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, max_frames=100, resize=(299, 299), model_name='inception'):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame.astype(np.float32) / 255.0 \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    # Preprocessing\n",
    "    frames = np.array(frames)\n",
    "    frames = preprocessing_functions[model_name](frames)\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_keyframes(frames, n_clusters=25):\n",
    "    flatten_frames = frames.reshape(frames.shape[0], -1) \n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(flatten_frames)\n",
    "    \n",
    "    keyframes_idx = []\n",
    "    for i in range(n_clusters):\n",
    "        distances = [np.linalg.norm(frame - kmeans.cluster_centers_[i]) for frame in flatten_frames]\n",
    "        keyframes_idx.append(np.argmin(distances))\n",
    "    \n",
    "    keyframes_idx.sort()\n",
    "    keyframes = frames[keyframes_idx]\n",
    "    return keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 25 frames\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_all_videos(csv_path, main_output_directory, model_name, max_seq_length):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    num_samples = len(df)\n",
    "    frame_features = np.zeros(shape=(num_samples, max_seq_length, NUM_FEATURES), dtype=\"float32\")\n",
    "    frame_masks = np.zeros(shape=(num_samples, max_seq_length, 1), dtype=\"bool\")\n",
    "    all_labels = []\n",
    "    \n",
    "    if model_name == 'inception':\n",
    "        img_size = (299, 299)\n",
    "    elif model_name == 'resnet':\n",
    "        img_size = (224, 224)\n",
    "    elif model_name == 'vgg':\n",
    "        img_size = (224, 224)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        video_path = os.path.join(main_output_directory, row['Video Name'])\n",
    "        label = row['normalized_labels']\n",
    "        \n",
    "        frames = load_video(video_path, resize=img_size)\n",
    "        frames = select_keyframes(frames)\n",
    "        frames = extract_features_from_frames(frames, model_name=model_name)\n",
    "        \n",
    "        sequence_length = frames.shape[0]\n",
    "        if sequence_length > max_seq_length:\n",
    "            frames = frames[:max_seq_length]\n",
    "            sequence_length = max_seq_length\n",
    "        elif sequence_length < max_seq_length:\n",
    "            frame_masks[idx, sequence_length:, :] = 1\n",
    "        \n",
    "        frame_features[idx, :sequence_length, :] = frames\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    return (frame_features, frame_masks), all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e11309",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = prepare_all_videos('train.csv', train_dir, model_name='inception', max_seq_length=max_seq_length)\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "'''Frame features in train set: (380, 25, 2048)\n",
    "Frame masks in train set: (380, 25, 1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1eb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train_features_25_inception.npz', train_features)\n",
    "np.save('train_labels_25_inception.npy', train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71753d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_features_25_inception.npz')\n",
    "train_features = train_data['features']\n",
    "train_masks = train_data['masks']\n",
    "train_labels = np.load('train_labels_25_inception.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e12e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = prepare_all_videos('test.csv', test_dir, model_name='inception', max_seq_length=max_seq_length)\n",
    "np.savez('test_features_25_inception.npz', features=test_features[0], masks=test_features[1])\n",
    "np.save('test_labels_25_inception.npy', test_labels)\n",
    "print(f\"Frame features in test set: {test_features[0].shape}\")   #Frame features in test set: (120, 25, 2048)\n",
    "print(f\"Frame masks in test set: {test_features[1].shape}\")  #Frame masks in test set: (120, 25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d223f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features, val_labels = prepare_all_videos('val_stage1.csv', val_dir, model_name='inception', max_seq_length=max_seq_length)\n",
    "np.savez('val_features_5_inception.npz', features=val_features[0], masks=val_features[1])\n",
    "np.save('val_labels_5_inception.npy', val_labels)\n",
    "print(f\"Frame features in validation set: {val_features[0].shape}\") # Frame features in validation set: (96, 25, 2048)\n",
    "print(f\"Frame masks in validation set: {val_features[1].shape}\") # Frame masks in validation set: (96, 25, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e77395",
   "metadata": {},
   "source": [
    "## Adding Sequence Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141452ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return 2 * ((self.precision.result() * self.recall.result()) /\n",
    "                    (self.precision.result() + self.recall.result() + tf.keras.backend.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_labels_resnet), y=train_labels_resnet)\n",
    "class_weights = dict(enumerate(weights))\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc000d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def inception_lstm_model():\n",
    "    frame_features_input = keras.Input((max_seq_length, NUM_FEATURES))\n",
    "    mask_input = keras.Input((max_seq_length,), dtype=\"bool\")\n",
    "\n",
    "    layer = keras.layers.LSTM(32, return_sequences=True, kernel_regularizer=regularizers.l2(0.01))(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    layer = keras.layers.Dropout(0.5)(layer)\n",
    "    layer = keras.layers.Dense(16, kernel_regularizer=regularizers.l2(0.01))(layer)\n",
    "    layer = keras.layers.Dropout(0.5)(layer)\n",
    "    output = keras.layers.Dense(1, activation=\"sigmoid\")(layer)\n",
    "\n",
    "    LSTM_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    LSTM_model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=[\n",
    "                  'accuracy',\n",
    "                  tf.keras.metrics.Precision(name='precision'),\n",
    "                  tf.keras.metrics.Recall(name='recall'),\n",
    "                  tf.keras.metrics.AUC(name='auc'),\n",
    "                  F1Score()\n",
    "              ])\n",
    "    )\n",
    "    return LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626462e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "def inception_lstm_experiment():\n",
    "    filepath = \"F:\\\\Augmented videos 20\\\\negin\\\\video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    seq_model = resnet_lstm_model()\n",
    "    history = seq_model.fit(\n",
    "    [train_features, train_masks],\n",
    "    train_labels,\n",
    "    validation_data=([val_features, val_masks], val_labels),\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    class_weight = class_weights\n",
    ")\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    loss, f1_score, auc = seq_model.evaluate([test_features, test_masks], test_labels)\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "    return history, seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef929f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sequence_model = resnet_lstm_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
