{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial: Trial):\n",
    "    # Hyperparameters to be optimized\n",
    "    n_layers = trial.suggest_categorical(\"n_layers\", [1, 2, 3])\n",
    "    n_units = trial.suggest_categorical(\"n_units\", [8, 16, 32, 64, 128])\n",
    "    dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [0.0001, 0.01, 0.01])\n",
    "    l1_reg = trial.suggest_categorical(\"l1_reg\", [0.01, 0.05, 0.1])\n",
    "    l2_reg = trial.suggest_categorical(\"l2_reg\", [0.01, 0.05, 0.1])\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten(), input_shape=(25, 7, 7, 2048)))\n",
    "    for i in range(n_layers):\n",
    "        return_sequences = True if i < n_layers - 1 else False\n",
    "        model.add(LSTM(n_units, return_sequences=return_sequences, kernel_regularizer=regularizers.l1_l2(l1=l1_reg, l2=l2_reg)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=[\n",
    "                      'accuracy',\n",
    "                      Precision(name='precision'),\n",
    "                      Recall(name='recall'),\n",
    "                      AUC(name='auc'),\n",
    "                      F1Score()\n",
    "                  ])\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial: Trial):\n",
    "    model = create_model(trial)\n",
    "    history = model.fit(\n",
    "        np.stack(train_features_resnet), np.array(train_labels_resnet),\n",
    "        validation_data=(np.stack(val_features_resnet), np.array(val_labels_resnet)),\n",
    "        epochs=50, batch_size=32,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "    )\n",
    "    # Optimize for validation AUC\n",
    "    return history.history[\"val_auc\"][-1]\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Results\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial AUC: {best_trial.value}\")\n",
    "print(\"Best trial params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test data\n",
    "y_pred = model.predict(np.stack(test_features_resnet))\n",
    "y_pred_bin = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(np.array(test_labels_resnet), y_pred_bin)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training & validation loss values per epoch\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot F1 Score\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title('Model F1 Score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and recall Curve\n",
    "precision, recall, _ = precision_recall_curve(test_labels_resnet, y_pred)\n",
    "prc_auc = auc(recall, precision)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('test')\n",
    "model_name = \"test\"\n",
    "legend_text = f'{model_name} (AUC = {prc_auc:.2f})'\n",
    "plt.legend([legend_text])\n",
    "\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "y_true = test_labels_resnet\n",
    "y_scores = y_pred\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
